{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습1] 이미지 데이터 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Numpy, PIL, tensorflow.keras 등을 이용하여 이미지를 Numpy 배열로 바꿔보고, 이를 통해 이미지가 어떻게 이루어졌는지 확인하기\n",
    "* import PIL: 이미지를 불러오고 처리하기 위한 라이브러리\n",
    "* PIL.Image.open(path): 이미지 불러오기\n",
    "* PIL.Image.resize(width, height): 이미지 크기 조정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from elice_utils import EliceUtils\n",
    "#elice_utils = EliceUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 목록을 불러오는 함수입니다.\n",
    "\n",
    "def load_data(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 1번\n",
    "   PIL.Image를 이용하여 \n",
    "   이름(경로+이름)을 바탕으로 이미지를 불러오고,\n",
    "   이를 리스트 'images'에 추가하는 함수를 완성합니다.\n",
    "   main 함수에서 'path'와 'names' 변수를 확인해보세요.\n",
    "'''\n",
    "\n",
    "def load_images(path, names):\n",
    "    \n",
    "    images=[]\n",
    "    for fname in names:\n",
    "        file_path = path + fname # 이미지 경로 지정\n",
    "        im = PIL.Image.open(file_path) # 이미지 불러오기\n",
    "        images.append(im) # 이미지 리스트에 추가\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 2번\n",
    "   이미지의 사이즈를 main 함수에 있는 'IMG_SIZE'로 \n",
    "   조정하고, 이를 Numpy 배열로 변환하는 함수를 완성합니다.\n",
    "'''\n",
    "\n",
    "def images2numpy(images, size):\n",
    "    \n",
    "    output = []\n",
    "    for im in images:\n",
    "        im_resize = im.resize(size) # 이미지 크기 조정\n",
    "        im_npy = np.array(im_resize) # 이미지 to 넘파이\n",
    "        output.append(im_npy) # 아웃풋 리스트에 추가\n",
    "        \n",
    "    output = np.array(output) # 최종 아웃풋도 넘파이 형태 \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지에 대한 정보를 나타내주는 함수입니다.\n",
    "\n",
    "def sampleVisualize(np_images):\n",
    "\n",
    "    fileName = \"./data/images/1000092795.jpg\"\n",
    "    ndarray = img.imread(fileName)\n",
    "    \n",
    "    plt.imshow(ndarray)\n",
    "    plt.show()    \n",
    "    plt.savefig(\"plot.png\")\n",
    "    \n",
    "    print(\"\\n1-1. 'fileName' 이미지(원본): \")\n",
    "    elice_utils.send_image(\"plot.png\")\n",
    "    \n",
    "    print('\\n1-2. Numpy array로 변환된 원본 이미지:', ndarray)\n",
    "    print('\\n1-3. Numpy array로 변환된 원본 이미지의 크기:', np.array(ndarray).shape)\n",
    "    \n",
    "    plt.imshow(np_images[0])\n",
    "    plt.show()\n",
    "    plt.savefig(\"plot_re.png\")\n",
    "    \n",
    "    print(\"\\n2-1. 'fileName' 이미지(resize 후): \")\n",
    "    elice_utils.send_image(\"plot_re.png\")\n",
    "    \n",
    "    print('\\n2-2. Numpy array로 변환된 resize 후 이미지:', np_images[0])\n",
    "    print('\\n2-3. Numpy array로 변환된 resize 후 이미지 크기:', np.array(np_images[0]).shape)    \n",
    "    \n",
    "    print('\\n3. Numpy array로 변환된 resize 후 이미지 10장의 크기:', np.array(np_images).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 3번\n",
    "   main 함수를 완성하세요.\n",
    "   \n",
    "   Step01. 이미지를 불러오는 함수를 이용해 \n",
    "           'images'를 정의합니다.\n",
    "   \n",
    "   Step02. 이미지를 Numpy 배열로 바꾸는 함수를 이용해\n",
    "           'np_images'를 정의합니다.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    CSV_PATH = \"./data/data.csv\"\n",
    "    IMG_PATH = \"./data/images/\"\n",
    "    IMG_SIZE = (300,300)\n",
    "    MAX_LEN = 30\n",
    "    BATCH_SIZE = 2\n",
    "    \n",
    "    name_caption = load_data(CSV_PATH)\n",
    "    names = name_caption['file_name']\n",
    "    print(names)\n",
    "    \n",
    "    images = load_images(path=IMG_PATH, names=names) # 이미지 불러오기\n",
    "    np_images = images2numpy(images, size=IMG_SIZE) # 이미지 넘파이로 변환하기\n",
    "    \n",
    "    sampleVisualize(np_images)\n",
    "    \n",
    "    return images, np_images\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습2] 일반 다층 퍼셉트론 모델(MLP)로 이미지 데이터 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 테스트용 MNIST 데이터를 96% 이상의 정확도로 분류하는 MLP모델을 만들고 학습하기\n",
    "* tf.keras.layers.Flatten(): 2차원 데이터를 1차원 데이터로 평평하게 만들어줌\n",
    "* tf.keras.layers.Dense(node, activation): MLP의 기본 layer\n",
    "* from tensorflow.keras.utils import to_categorical: label을 클래스화 하는 원-핫 인코딩 모듈\n",
    "* label = to_categorical(label, 10): 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from visual import *\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# 동일한 실행 결과 확인을 위한 코드입니다.\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 1번\n",
    "   MNIST 데이테 셋을 전처리하는 'preprocess' 함수를 완성합니다.\n",
    "\n",
    "   Step01. MNIST 데이터 이미지를 0~1 사이 값으로 정규화해줍니다.\n",
    "           원본은 0~255 사이의 값입니다.\n",
    "           \n",
    "   Step02. 0~9 사이 값인 label을 클래스화 하기 위해 \n",
    "           원-핫 인코딩을 진행합니다.\n",
    "\n",
    "'''\n",
    "\n",
    "def preprocess():\n",
    "    \n",
    "    # MNIST 데이터 세트를 불러옵니다.\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    \n",
    "    # MNIST 데이터 세트를 Train set과 Test set으로 나누어 줍니다.\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
    "    \n",
    "    # 이미지 정규화\n",
    "    train_images = train_images/255.\n",
    "    test_images = test_images/255.\n",
    "    \n",
    "    # 원-핫 인코딩\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "    \n",
    "    return train_images, test_images, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 2번\n",
    "   다층 퍼셉트론(MLP) 모델을 생성합니다.\n",
    "\n",
    "'''\n",
    "def MLP():\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28,28))) # input layer\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))  # output layer\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 3번\n",
    "   모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "   Step01. MLP 함수를 통해 모델을 불러옵니다.\n",
    "   \n",
    "   Step02. 모델의 손실 함수, 최적화 알고리즘, 평가 방법을 설정합니다.\n",
    "   \n",
    "   Step03. 모델의 구조를 확인하는 코드를 작성합니다.\n",
    "   \n",
    "   Step04. 모델을 학습시킵니다. 검증용 데이터도 설정하세요.\n",
    "           'epochs'와 'batch_size'도 자유롭게 설정하세요.\n",
    "              \n",
    "   Step05. 모델을 테스트하고 손실(loss)값과 \n",
    "           Test Accuracy 값 및 예측 클래스, \n",
    "           손실 함수값 그래프를 출력합니다. \n",
    "           \n",
    "           모델의 성능을 확인해보고,\n",
    "           목표값을 달성해보세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # 데이터를 불러옵니다.\n",
    "    train_images, test_images, train_labels, test_labels = preprocess()\n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = MLP()\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images, train_labels, epochs=6, batch_size=128, verbose=2,\n",
    "                        validation_data = (test_images, test_labels))\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
    "    \n",
    "    Visulaize([('MLP', history)], 'loss')\n",
    "    \n",
    "    return test_acc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습3] Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convolution Layer를 구성하는 방법 알아보기\n",
    "* keras.layers.Conv2D(filters, kernal_size, strides, padding, activation)(image)\n",
    "\n",
    " -filters: output filter의 개수\n",
    " \n",
    " -kernel_size: Convolution을 위한 kernel    \n",
    " \n",
    " -strides: 정수 및 튜플, 리스트 형태의 값 ex) (2,2)      \n",
    " \n",
    " -padding: SAME(패딩 O) / VALID(패딩 X)\n",
    " \n",
    " -activation: 활성화 함수 ex) relu, softmax\n",
    " \n",
    " -image: 입력 영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualize(image, x, y):\n",
    "    plt.imshow(image.reshape(x,y), cmap ='Greys')\n",
    "    plt.savefig('plot.png')\n",
    "    elice_utils.send_image(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 3 x 3 x 1 영상을 하나 만들어줍니다.\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]],\n",
    "                   [[7],[8],[9]]]], dtype = np.float32)\n",
    "\n",
    "# 합성곱 연산을 위해 임의의 2 x 2 x 1 커널을 하나 만들어줍니다.\n",
    "kernel = np.array([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 Shape 출력 : (num of image, width, height, channel)\n",
    "print('Image shape : ', image.shape)\n",
    "# 커널 Shape 출력 : (width, height, channel, num of kernel)\n",
    "print('Kernel shape : ', kernel.shape)\n",
    "# tf.nn.conv2d에 넣기 위해 이미지와 커널의 Shape을 위와 같이 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gray 이미지 출력\n",
    "Visualize(image, 3 ,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = tf.constant_initializer(kernel)\n",
    "# Convolution Layer 선언\n",
    "'''\n",
    "지시사항1번 \n",
    "   keras.layers.Conv2D()를 완성하세요.\n",
    "'''\n",
    "conv2d = keras.layers.Conv2D(filters=1, kernel_size=2, padding='VALID', kernel_initializer=kernel_init)(image)\n",
    "Visualize(conv2d.numpy(), 2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습4] Max Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pooling Layer: Convolution Layer의 결과(Feature Map)를 축소시키는데 사용하는 층\n",
    "* Feature map 사이즈 다운 -> 연산량 감소\n",
    "* Feature 개수 감소 -> Overfitting 방지\n",
    "* keras.layers.MaxPool2D(pool_size, strides, padding)\n",
    "\n",
    " -pool_size: Pooling filter의 크기\n",
    " \n",
    " -strides: Filter를 적용할 간격\n",
    " \n",
    " -padding: SAME or VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualize(image, x, y):\n",
    "    plt.imshow(image.reshape(x,y), cmap ='Greys')\n",
    "    plt.savefig('plot.png')\n",
    "    elice_utils.send_image(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 3 x 3 x 1 영상을 하나 만들어줍니다.\n",
    "image = tf.constant([[[[1],[2],[3],[4]],\n",
    "                   [[4],[5],[6],[7]],\n",
    "                   [[7],[8],[9],[10]],\n",
    "                   [[3],[5],[7],[9]]]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 1번\n",
    "Max Pooling Layer를 선언하세요.\n",
    "''' \n",
    "pool = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='VALID')(image)\n",
    "\n",
    "print(pool.shape)\n",
    "print(pool.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 영상과 Max Pooling 후 영상을 출력합니다..\n",
    "Visualize(image.numpy(), 4,4)\n",
    "Visualize(pool.numpy(), 2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습5] Keras로 CNN 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 테스트용 MNIST 데이터를 95% 이상의 정확도로 분류하는 CNN 모델 만들기\n",
    "* tf.keras.layers.Conv2D(filters, kernel_size, activation, padding): 입력 이미지의 피처맵을 추출하는 레이어\n",
    "* tf.keras.layers.MaxPool2D(padding): 처리할 피처맵의 크기를 줄여주는 레이어\n",
    "* tf.keras.layers.Flatten(): Conv/Pooling의 결과는 N-차원의 텐서 형태, 이를 1차원으로 평평하게 만들어줌\n",
    "* tf.keras.layers.Dense(node, activation): Fully Connected Layer(=MLP)\n",
    "* np.expand_dims(data, axis): Numpy 배열 데이터에서 마지막 축(axis)에 해당하는 곳에 차원 하나 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from visual import *\n",
    "from plotter import *\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# 동일한 실행 결과 확인을 위한 코드입니다.\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 1번\n",
    "MNIST 데이테 셋을 전처리하는 'preprocess' 함수를 완성합니다.\n",
    "   \n",
    "   Step01과 Step03은 이전 실습과 동일한 코드를 사용할 수 있습니다.\n",
    "\n",
    "   Step01. MNIST 데이터 이미지를 0~1 사이 값으로 정규화해줍니다.\n",
    "           원본은 0~255 사이의 값입니다.\n",
    "           \n",
    "   Step02. MNIST 데이터의 채널 차원을 추가해줍니다.\n",
    "           \n",
    "   Step03. 0~9 사이 값인 레이블을 클래스화 하기 위해 원-핫 인코딩을 진행합니다.\n",
    "   \n",
    "'''\n",
    "\n",
    "def preprocess():\n",
    "    \n",
    "    # MNIST 데이터 세트를 불러옵니다.\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    \n",
    "    # MNIST 데이터 세트를 Train set과 Test set으로 나누어 줍니다.\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
    "    \n",
    "    # Train 데이터 5000개와 Test 데이터 1000개를 사용합니다.\n",
    "    train_images, train_labels = train_images[:5000], train_labels[:5000]\n",
    "    test_images, test_labels = test_images[:1000], test_labels[:1000]\n",
    "    \n",
    "    # Step01. 이미지 정규화\n",
    "    train_images = train_images/255.\n",
    "    test_images = test_images/255.\n",
    "    \n",
    "    # Step02. 데이터 차원 추가 for Conv\n",
    "    train_images = np.expand_dims(train_images, axis=-1)\n",
    "    test_images = np.expand_dims(test_images, axis=-1)\n",
    "    \n",
    "    # Step03. 원-핫 인코딩\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "    \n",
    "    return train_images, test_images, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 2번\n",
    "CNN 모델을 생성합니다.\n",
    "'''\n",
    "def CNN():\n",
    "    \n",
    "    # 모델 구축\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    model.add(tf.keras.layers.Input(shape=(28, 28, 1))) \n",
    "    \n",
    "    # conv + pooling\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding='VALID'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding='VALID'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(2, padding='VALID'))\n",
    "    \n",
    "    # output layer(MLP)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "지시사항 3번\n",
    "모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "   Step01. CNN 함수를 통해 모델을 불러옵니다.\n",
    "   \n",
    "   Step02. 모델의 손실 함수, 최적화 알고리즘, 평가 방법을 설정합니다.\n",
    "   \n",
    "   Step03. 모델의 구조를 확인하는 코드를 작성합니다.\n",
    "   \n",
    "   Step04. 모델을 학습시킵니다. 검증용 데이터도 설정하세요.\n",
    "           'epochs'와 'batch_size'도 자유롭게 설정하세요.\n",
    "           단, 'epochs'이 클수록, 'batch_size'는 작을수록 학습 속도가 느립니다.\n",
    "   \n",
    "   Step05. 모델을 테스트하고 손실(loss)값과 Test Accuracy 값 및 예측 클래스, \n",
    "           손실 함수값 그래프를 출력합니다. 모델의 성능을 확인해보고,\n",
    "           목표값을 달성해보세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # 데이터를 불러옵니다.\n",
    "    train_images, test_images, train_labels, test_labels = preprocess()\n",
    "    \n",
    "    # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
    "    model = CNN()\n",
    "    \n",
    "    # 모델의 구조를 확인합니다.\n",
    "    model.summary()\n",
    "    \n",
    "    # 컴파일러를 설정합니다.\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # fit 함수를 사용하여 모델을 학습합니다.\n",
    "    # 학습 수행 시 정보는 history에 저장합니다.\n",
    "    history = model.fit(train_images, train_labels, epochs=6, batch_size=128, verbose=2,\n",
    "                        validation_data=(test_images, test_labels))\n",
    "    \n",
    "    # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
    "    loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    \n",
    "    print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
    "    print('예측한 Test Data 클래스 : ',model.predict_classes(test_images)[:10])\n",
    "    \n",
    "    Visulaize([('CNN', history)], 'loss')\n",
    "    \n",
    "    Plotter(test_images, model)\n",
    "    \n",
    "    return test_acc\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
